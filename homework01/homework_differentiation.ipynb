{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it easy to google every task please please please try to undestand what's going on. The \"just answer\" thing will be not counted, make sure to present derivation of your solution. It is absolutely OK if you found an answer on web then just exercise in $\\LaTeX$ copying it into here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links: \n",
    "[1](http://www.machinelearning.ru/wiki/images/2/2a/Matrix-Gauss.pdf)\n",
    "[2](http://www.atmos.washington.edu/~dennis/MatrixCalculus.pdf)\n",
    "[3](http://cal.cs.illinois.edu/~johannes/research/matrix%20calculus.pdf)\n",
    "[4](http://research.microsoft.com/en-us/um/people/cmbishop/prml/index.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \n",
    "y = x^Tx,  \\quad x \\in \\mathbb{R}^N \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = \n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Well, we can write out the expression for $y$ to get\n",
    "$$\n",
    "y = \\sum x_i^2\n",
    "$$\n",
    "So then, as\n",
    "$$\n",
    "\\frac{dy}{dx} = \\left[\\frac{dy}{dx_1},\\ \\dots,\\ \\frac{dy}{dx_N}\\right]\n",
    "$$\n",
    "we have\n",
    "$$\n",
    "\\frac{dy}{dx} = 2x^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = tr(AB) \\quad A,B \\in \\mathbb{R}^{N \\times N} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dA} =\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we partition $A$ into column vectors $[a_1, \\dots, a_N]$, and $B^T$ into column vectors $[b_1, \\dots, b_N]$, then\n",
    "$$\n",
    "tr(AB) = \\sum a_i b_i^T\n",
    "$$\n",
    "From this we can see easily that element $a_{ij}$ enters the sum only in $a_{ij} b_{ij}$. Thus\n",
    "$$\n",
    "\\frac{dy}{dA} = B^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$  \n",
    "y = x^TAc , \\quad A\\in \\mathbb{R}^{N \\times N}, x\\in \\mathbb{R}^{N}, c\\in \\mathbb{R}^{N} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} =\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dA} =\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint for the latter (one of the ways): use *ex. 2* result and the fact \n",
    "$$\n",
    "tr(ABC) = tr (CAB)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "For the first one, we can just say that $Ac = z$, so then we have $y = x^T z$. Then we can use the previous result to get\n",
    "$$\n",
    "\\frac{dy}{dx} = c^T A^T\n",
    "$$\n",
    "\n",
    "For the second one, let $X$ be a matrix with the first column equal to $x$ and the rest of entries equal to 0, and $C$ a matrix with first column equal to $c$, with the rest of entries equal to 0. Then, $x^T A c$ is equal to first row-first column entry of $X^T A C$. Furthermore, all other entries of this matrix will be zero, so then $tr(X^T A C) = x^T A c$. So using the trace cyclicality property we know that $tr(X^T A C) = tr(A C X^T)$. Now we can use the previous exercise to get that\n",
    "$$\n",
    "\\frac{dy}{dA} = X C^T = x c^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex. 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic matrix factorization example. Given matrix $X$ you need to find $A$, $S$ to approximate $X$. This can be done by simple gradient descent iteratively alternating $A$ and $S$ updates.\n",
    "$$\n",
    "J = || X - AS ||_F^2  , \\quad A\\in \\mathbb{R}^{N \\times R} , \\quad S\\in \\mathbb{R}^{R \\times M}\n",
    "$$\n",
    "$$\n",
    "\\frac{dJ}{dS} = ? \n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First approach\n",
    "Using ex.2 and the fact:\n",
    "$$\n",
    "|| X ||_F^2 = tr(XX^T) \n",
    "$$ \n",
    "it is easy to derive gradients (you can find it in one of the refs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second approach\n",
    "You can use *slightly different techniques* if they suits you. Take a look at this derivation:\n",
    "<img src=\"grad.png\">\n",
    "(excerpt from [Handbook of blind source separation, Jutten, page 517](https://books.google.ru/books?id=PTbj03bYH6kC&printsec=frontcover&dq=Handbook+of+Blind+Source+Separation&hl=en&sa=X&ved=0ahUKEwi-q_apiJDLAhULvXIKHVXJDWcQ6AEIHDAA#v=onepage&q=Handbook%20of%20Blind%20Source%20Separation&f=false), open for better picture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third approach\n",
    "And finally we can use chain rule! **YOUR TURN** to do it.\n",
    "let $ F = AS $ \n",
    "\n",
    "**Find**\n",
    "$$\n",
    "\\frac{dJ}{dF} =  \n",
    "$$ \n",
    "and \n",
    "$$\n",
    "\\frac{dF}{dS} =  \n",
    "$$ \n",
    "(the shape should be $ NM \\times RM )$.\n",
    "\n",
    "Now it is easy do get desired gradients:\n",
    "$$\n",
    "\\frac{dJ}{dS} =  \n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "This approach is dumb. It relies on some bullshit conventions about the shape of the matrix by matrix derivative, which are not explained anywhere (and this should be a tensor anyways). So let's do the old school chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{dJ}{dS_{ij}} = \\sum_{kl} \\frac{dJ}{dF_{kl}} \\frac{dF_{kl}}{dS_{ij}}\n",
    "$$\n",
    "\n",
    "Since $J = \\sum_{ij} (X_{ij}-F_{ij})^2$, we have that the first term equals\n",
    "$$\n",
    "\\frac{dJ}{dF_{kl}} = 2(F_{kl}- X_{kl})\n",
    "$$\n",
    "Next, as $F_{kl} = a_k^T s_{l}$, where $a_k$ is the $k$th column vector of $A^T$ and $s_l$ is the $l$th column vector of $S$, we have that\n",
    "$$\n",
    "\\frac{dF_{kl}}{dS_{ij}} = a_{ki},\\ \\text{if $l=j$, 0 otherwise}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So then we have\n",
    "$$\n",
    "\\frac{dJ}{dS_{ij}} = \\sum_{k} 2(F_{kj} - X_{kj}) A_{ki} = 2 ([A^T A S]_{ij} - [A^T X]_{ij}) = 2[A^T A S - A^T X]_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, clearly,\n",
    "$$\n",
    "\\frac{dJ}{dS} = 2(A^T A S - A^T X)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
